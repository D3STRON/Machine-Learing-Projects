{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df6cebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, get_linear_schedule_with_warmup, AdamW\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import datasets \n",
    "# from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba719c7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "308f37cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22981ecbb7a479e8f1294b557fdffa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fc1bb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>See me, ancient one! Dismal Tuat, Nergal unsaf...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Feels like Im covered in lies so turn off the ...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Works of art, painted black Magniloquent, blee...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Into the cage like an animal You must survive ...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Paralysed in pleasure I hear you call Lost my ...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>499995</td>\n",
       "      <td>[Verse 1] I dont want to tell you that its ove...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>499996</td>\n",
       "      <td>I get to thinking sometimes I dont know why I ...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>499997</td>\n",
       "      <td>When I was A little boy around the table athom...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>499998</td>\n",
       "      <td>[Verse 1] Its a junked out joint off a backroa...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>499999</td>\n",
       "      <td>Well I went to church last Sunday So I could s...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                              Lyric    genre\n",
       "0                0  See me, ancient one! Dismal Tuat, Nergal unsaf...    Metal\n",
       "1                1  Feels like Im covered in lies so turn off the ...    Metal\n",
       "2                2  Works of art, painted black Magniloquent, blee...    Metal\n",
       "3                3  Into the cage like an animal You must survive ...    Metal\n",
       "4                4  Paralysed in pleasure I hear you call Lost my ...    Metal\n",
       "...            ...                                                ...      ...\n",
       "499995      499995  [Verse 1] I dont want to tell you that its ove...  country\n",
       "499996      499996  I get to thinking sometimes I dont know why I ...  country\n",
       "499997      499997  When I was A little boy around the table athom...  country\n",
       "499998      499998  [Verse 1] Its a junked out joint off a backroa...  country\n",
       "499999      499999  Well I went to church last Sunday So I could s...  country\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(line):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s,.!?[\\]]')\n",
    "    line = pattern.sub('', line)\n",
    "    line = re.sub(r'\\s+', ' ', line).strip()\n",
    "    return line\n",
    "\n",
    "# lyrics_train_df = pd.read_csv('./data/lyrics_train.csv')  # No need for index_col=False, as it's False by default\n",
    "# lyrics_train_df['Lyric'] = lyrics_train_df['Lyric'].str.replace(\"\\r\\n\", \" \").str.replace(\"\\r\", \" \").str.replace(\"\\n\", \" \")\n",
    "# lyrics_train_df['Lyric'] = lyrics_train_df['Lyric'].apply(clean_text)\n",
    "# lyrics_train_df.to_csv('./cleaned_train_lyrics.csv', index=False)\n",
    "lyrics_train_df = pd.read_csv('./data/cleaned_train_lyrics.csv')\n",
    "\n",
    "lyrics_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cede3713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>can you hear me call your name Im not far away...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>You say you are so clever You beleive that you...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Walking across these misery plains When all fo...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fuck you you bitch get out of my head Twisting...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Crashing forth upon the soil Filthy waves gave...</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>[Verse 1] When the sun sinks down and dreams s...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>I watched from the window as she slipped from ...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>Look around, it is never far See who the wound...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>We started arguing on the onramp Of Interstate...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>This must be my lucky day Babys back again Sai...</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              Lyric    genre\n",
       "0               0  can you hear me call your name Im not far away...    Metal\n",
       "1               1  You say you are so clever You beleive that you...    Metal\n",
       "2               2  Walking across these misery plains When all fo...    Metal\n",
       "3               3  Fuck you you bitch get out of my head Twisting...    Metal\n",
       "4               4  Crashing forth upon the soil Filthy waves gave...    Metal\n",
       "...           ...                                                ...      ...\n",
       "49995       49995  [Verse 1] When the sun sinks down and dreams s...  country\n",
       "49996       49996  I watched from the window as she slipped from ...  country\n",
       "49997       49997  Look around, it is never far See who the wound...  country\n",
       "49998       49998  We started arguing on the onramp Of Interstate...  country\n",
       "49999       49999  This must be my lucky day Babys back again Sai...  country\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(line):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9\\s,.!?[\\]]')\n",
    "    line = pattern.sub('', line)\n",
    "    line = re.sub(r'\\s+', ' ', line).strip()\n",
    "    return line\n",
    "\n",
    "# lyrics_test_df = pd.read_csv('./data/lyrics_test.csv')  # No need for index_col=False, as it's False by default\n",
    "# lyrics_test_df['Lyric'] = lyrics_test_df['Lyric'].str.replace(\"\\r\\n\", \" \").str.replace(\"\\r\", \" \").str.replace(\"\\n\", \" \")\n",
    "# lyrics_test_df['Lyric'] = lyrics_test_df['Lyric'].apply(clean_text)\n",
    "# lyrics_test_df.to_csv('./data/cleaned_test_lyrics.csv', index=False)\n",
    "lyrics_test_df = pd.read_csv('./data/cleaned_test_lyrics.csv')\n",
    "\n",
    "lyrics_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9340adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_df):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.lyric_list = []\n",
    "        self.end_of_text_token = \"<|endoflyric|>\"\n",
    "        \n",
    "        for lyric, genre in tqdm(zip(lyrics_df['Lyric'],lyrics_df['genre'] ), total=len(lyrics_df['genre'])):\n",
    "            lyric_str = f\"LYRIC[{genre.lower()}]:{lyric}{self.end_of_text_token}\"\n",
    "#             lyric_str = f\"LYRIC:{lyric}{self.end_of_text_token}\"\n",
    "            self.lyric_list.append(lyric_str)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.lyric_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.lyric_list[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04fc1582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a5082390cd4619906a6b6fcfae9cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_data = LyricsDataset(lyrics_train_df)\n",
    "test_data = LyricsDataset(lyrics_test_df)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6282548",
   "metadata": {},
   "source": [
    "# Training Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "267ef1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.to(device)\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    'pad_token':'<|pad|>'\n",
    "                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perp(model, tokenizer, test_loader):\n",
    "    model.eval()\n",
    "    nlls = []\n",
    "    for lyric in tqdm(test_loader):\n",
    "        lyric_tens = tokenizer(lyric, padding=True, truncation= True, return_tensors='pt')['input_ids'].to(device)\n",
    "        target_tens = lyric_tens.clone()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(lyric_tens, labels=target_tens)\n",
    "            neg_log_likelihood = outputs.loss\n",
    "            nlls.append(neg_log_likelihood)\n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "    print(\"Evaluations:\", ppl.item())\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc7fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 5e-6\n",
    "WARMUP_STEPS = 80000\n",
    "EVAL_STEPS = 100000\n",
    "PRINT_STEPS = 100\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)\n",
    "proc_seq_count = 0\n",
    "\n",
    "\n",
    "proc_seq_count = 0\n",
    "sum_loss = 0.0\n",
    "batch_count = 0\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "979cf022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 started==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ed1c4d615a49ca93aeba330f6a6ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m started\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx,lyric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[1;32m----> 7\u001b[0m     lyric_tens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlyric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(lyric_tens, labels \u001b[38;5;241m=\u001b[39m lyric_tens\u001b[38;5;241m.\u001b[39mclone())\n\u001b[0;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m/\u001b[39m BATCH_SIZE\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
    "    \n",
    "    for idx,lyric in enumerate(tqdm(train_loader)):\n",
    "        lyric_tens = tokenizer(lyric, padding=True, return_tensors='pt', truncation= True)['input_ids'].to(device)\n",
    "        output = model(lyric_tens, labels = lyric_tens.clone())\n",
    "        loss = output['loss']  / BATCH_SIZE\n",
    "        loss.backward()\n",
    "        sum_loss = sum_loss + output['loss'].detach().data\n",
    "        \n",
    "        proc_seq_count = proc_seq_count + 1\n",
    "        steps += 1\n",
    "        if proc_seq_count == BATCH_SIZE:\n",
    "            proc_seq_count = 0    \n",
    "            batch_count += 1\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "\n",
    "        if batch_count == PRINT_STEPS:\n",
    "            print(f\"sum loss {sum_loss}\")\n",
    "            batch_count = 0\n",
    "            sum_loss = 0.0\n",
    "        if steps > EVAL_STEPS:\n",
    "            steps = 0\n",
    "            calc_perp(model, tokenizer, test_loader)\n",
    "            model.push_to_hub(\"multi-genre-mdeium\")\n",
    "            tokenizer.push_to_hub(\"multi-genre-mdeium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00cd58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_lyrics = ' '.join(train_data.lyric_list)\n",
    "with open('train.txt', 'w') as file:\n",
    "    file.write(merged_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72842159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(\n\u001b[0;32m     17\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Initialize Trainer\u001b[39;00m\n\u001b[0;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     22\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     23\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     24\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m---> 25\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtokenized_train_dataset\u001b[49m,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m     29\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a PyTorch dataset\n",
    "\n",
    "# dataset = TextDataset(file_path='./train.txt', tokenizer = tokenizer, block_size=128)\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Define the data collator for language modeling\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./gpt2-finetuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b55b6f",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dac37326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcc3a4ffd984097a77b3c2f682df26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/692 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a039f417c4914519b35fee467898c8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007f6d07170840f69d900f136804137f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba7f305fa5a4b23ada4095b9bdfe162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e11435c2e5d413ba1e6d7c62e960b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d774881d82f74930be59a83f9472359d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/907 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9aa8ef54dd427fb8d073ceca6e0a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4886d7bdc904442a8218730a64fdfc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "model.to(device)\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    \n",
    "    \n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"D3STRON/multi-genre\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"D3STRON/multi-genre\")\n",
    "model.to(device)\n",
    "\n",
    "def evaluate(model, tokenizer, test_loader):\n",
    "    model.eval()\n",
    "    nlls = []\n",
    "    EVAL_STEPS = 1000\n",
    "    steps = 0\n",
    "    for lyric in tqdm(test_loader):\n",
    "        lyric_tens = tokenizer(lyric, padding=True, truncation= True, return_tensors='pt')['input_ids'].to(device)\n",
    "        target_tens = lyric_tens.clone()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(lyric_tens, labels=target_tens)\n",
    "            neg_log_likelihood = outputs.loss\n",
    "            nlls.append(neg_log_likelihood)\n",
    "        if EVAL_STEPS == steps:\n",
    "            steps = 0\n",
    "            ppl = torch.exp(torch.stack(nlls).mean())\n",
    "            print(\"Evaluations:\", ppl.item())\n",
    "        steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24bd75e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d955113a821941d49304ee9c08e73516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluations: 27.740510940551758\n",
      "Evaluations: 26.603811264038086\n",
      "Evaluations: 26.785919189453125\n",
      "Evaluations: 26.821252822875977\n",
      "Evaluations: 27.183765411376953\n",
      "Evaluations: 27.136268615722656\n",
      "Evaluations: 27.177303314208984\n",
      "Evaluations: 27.196359634399414\n",
      "Evaluations: 27.12485122680664\n",
      "Evaluations: 27.163423538208008\n",
      "Evaluations: 27.157976150512695\n",
      "Evaluations: 27.14735221862793\n",
      "Evaluations: 27.218719482421875\n",
      "Evaluations: 27.233110427856445\n",
      "Evaluations: 27.29927635192871\n",
      "Evaluations: 27.239599227905273\n",
      "Evaluations: 27.297298431396484\n",
      "Evaluations: 27.316625595092773\n",
      "Evaluations: 27.3855037689209\n",
      "Evaluations: 27.40495491027832\n",
      "Evaluations: 27.37411117553711\n",
      "Evaluations: 27.335006713867188\n",
      "Evaluations: 27.335227966308594\n",
      "Evaluations: 27.307645797729492\n",
      "Evaluations: 27.299360275268555\n",
      "Evaluations: 27.262853622436523\n",
      "Evaluations: 27.25752830505371\n",
      "Evaluations: 27.244897842407227\n",
      "Evaluations: 27.23702049255371\n",
      "Evaluations: 27.250316619873047\n",
      "Evaluations: 27.254976272583008\n",
      "Evaluations: 27.26841163635254\n",
      "Evaluations: 27.265132904052734\n",
      "Evaluations: 27.252805709838867\n",
      "Evaluations: 27.19631576538086\n",
      "Evaluations: 27.20775604248047\n",
      "Evaluations: 27.247905731201172\n",
      "Evaluations: 27.280778884887695\n",
      "Evaluations: 27.284317016601562\n",
      "Evaluations: 27.274255752563477\n",
      "Evaluations: 27.246204376220703\n",
      "Evaluations: 27.253650665283203\n",
      "Evaluations: 27.256107330322266\n",
      "Evaluations: 27.27863121032715\n",
      "Evaluations: 27.25990867614746\n",
      "Evaluations: 27.26728057861328\n",
      "Evaluations: 27.247074127197266\n",
      "Evaluations: 27.234519958496094\n",
      "Evaluations: 27.24855613708496\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, tokenizer, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1828d43e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d9420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"D3STRON/multi_genre_music_generator\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"D3STRON/multi_genre_music_generator\")\n",
    "model.to(device)\n",
    "\n",
    "def choose_from_top(probs, cur_ids, n=7, no_rep=2):\n",
    "    ind = np.argpartition(probs, -n)[-n:]\n",
    "    top_prob = probs[ind]\n",
    "    top_prob /= np.sum(top_prob)  # Normalize\n",
    "\n",
    "    cur_ids_list = cur_ids.squeeze().cpu().numpy().tolist()\n",
    "    for i in range(200):\n",
    "        if i < 4:\n",
    "            choice = np.random.choice(ind, 1)[0]\n",
    "        else:\n",
    "            choice = np.random.choice(ind, 1, p=top_prob)[0]\n",
    "        n_gram = cur_ids_list[-no_rep + 1 :] + [choice]\n",
    "        if any(cur_ids_list[i : i + no_rep] == n_gram for i in range(len(cur_ids_list) - no_rep + 1)):\n",
    "            continue\n",
    "        return choice\n",
    "    return np.random.choice(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e93529a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LYRIC[pop]:A bundle of joy A promise that could not be fulfilled The world is filled with love and happiness And all that I want for you is a place in the sky But you cant find me on your knees And the sun wont set on my heart But its all right for me And youre a part in a beautiful life And I dont have no shame But Ive never known the way you feel Youre the love that you never knew you needed I know the world has been full for years but youve always been here For\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    cur_ids = tokenizer(\"LYRIC[pop]:A bundle of joy\", padding=True, return_tensors='pt', truncation= True)['input_ids'].to(device)\n",
    "    for i in range(100):\n",
    "        outputs = model(cur_ids, labels=cur_ids)\n",
    "        logits = outputs['logits']\n",
    "        softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n",
    "        if i == 3:\n",
    "            n = 30\n",
    "        else:\n",
    "            n = 5\n",
    "        next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), cur_ids, n=n) #Randomly(from the topN probability distribution) select the next word\n",
    "        cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n",
    "\n",
    "        if next_token_id in tokenizer.encode('<|endoflyric|>'):\n",
    "            joke_finished = True\n",
    "            break\n",
    "\n",
    "    output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
    "    output_text = tokenizer.decode(output_list)\n",
    "    print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1be3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
